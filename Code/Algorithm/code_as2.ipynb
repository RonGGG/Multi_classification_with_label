{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "as2_terminator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf55195229764822817e19cc68789990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4626a5369c24940a6c7c9f82ce64e27",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3f421e7291e48ee96df68e9cd4c1361",
              "IPY_MODEL_2496c2e4de94475e879dd4a1c13a9eda"
            ]
          }
        },
        "d4626a5369c24940a6c7c9f82ce64e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3f421e7291e48ee96df68e9cd4c1361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_795deb7799ca4efcb2b9dabf5844af67",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_367e4891f7ac44a590e19155ac56a32d"
          }
        },
        "2496c2e4de94475e879dd4a1c13a9eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1771c62bbb0c48c8b60c88ac5918a8e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 174MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c833eb66c46c4517a735df805b4f47ce"
          }
        },
        "795deb7799ca4efcb2b9dabf5844af67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "367e4891f7ac44a590e19155ac56a32d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1771c62bbb0c48c8b60c88ac5918a8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c833eb66c46c4517a735df805b4f47ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRpkWNiEawuH"
      },
      "source": [
        "# README\n",
        "## Instruction for code runninng:\n",
        "1. To start with running the cells in the 'Loading data from the google drive' to download the data. \n",
        "2. Run the cell in the 'Define fix parameter' to define the data path. \n",
        "3. The cells in 'Define Helper Functions' section need to be executed to make sure data preprocessing and training process run smoothly. \n",
        "4. The 'Define hyper parameters part' define the lstm layers, lstm hidden units, pretrain cnn model used to extract image, epoch to run and learning rate. User can adjust these paramters to achieve different performance. \n",
        "5. To experiment with the effect of pos weight for the loss function, go to 'Training process' section and 'Define model, loss function and optimizer' section, uncomment the code with pos_weight added.\n",
        "6. After adjusting the hyper parameters, sequentially execute the following sections to train the model and make predictions on the test dataset\n",
        "\n",
        "## !!!NOTE: \n",
        "This code is the version for running on colab. If you want to run on local device, you HAVE TO:\n",
        "\n",
        "1. change the path of data and csv files in 'Define fix parameter'\n",
        "2. comment the 'Loading data from the google drive' part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qOr9AgmTPyR",
        "outputId": "bdb95c9c-e2ae-4f99-d18c-0e4ce612f811"
      },
      "source": [
        "import pandas as pd \n",
        "import re\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import copy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import random\n",
        "from sklearn import metrics\n",
        "from gensim.models import KeyedVectors\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQJCYHq-I_Xc"
      },
      "source": [
        "# Loading data from the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "406moCb4TVJL"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mDudHqETWlP"
      },
      "source": [
        "id = '1aB6M6YLGXM4u2F8eyb8_iHRLCRzM-Vm4'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('2021s1comp5329assignment2.zip')  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huas_cHwTgmZ"
      },
      "source": [
        "! unzip -qq 2021s1comp5329assignment2.zip "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oImljHuI17r"
      },
      "source": [
        "# Define fix parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KImWg-H1Uyqv"
      },
      "source": [
        " # change your path here\n",
        "img_dir = './COMP5329S1A2Dataset/data/'\n",
        "test_csv_dir = './COMP5329S1A2Dataset/test.csv'\n",
        "train_csv_dir = './COMP5329S1A2Dataset/train.csv'\n",
        "seq_len = 49 # max sequence length for captions"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83rMrLX8JP7P"
      },
      "source": [
        "# Define Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fJ1b6p6TiPv"
      },
      "source": [
        "# remove all the punctuation in the captions\n",
        "def remove_punctuation_re(x):\n",
        "    x = x.lower()\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    return x\n",
        "\n",
        "# changing the labels to one hot vector\n",
        "def convert_label_to_vector(labels):\n",
        "    label_arr = np.zeros(20)\n",
        "    parsed_label = [int(x) for x in labels.split()]\n",
        "    for index in parsed_label:\n",
        "        label_arr[index] = 1\n",
        "    return label_arr"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUUiNgE7USnp"
      },
      "source": [
        "# preprocessing for captions, this function will remove all the punctuations,\n",
        "# tokenize the captions into list of words, and then lemmatize each word in the list.\n",
        "def data_preprocess(data_path, img_dir, train=True):\n",
        "    with open(data_path) as file:\n",
        "        lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
        "    df = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
        "    df['Image_Path'] = df['ImageID'].map(lambda x: img_dir + x)\n",
        "    df['Caption'] = df['Caption'].map(lambda x: remove_punctuation_re(x))\n",
        "    df['Caption'] = df['Caption'].map(lambda x: nltk.word_tokenize(x))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    # lemmatization process\n",
        "    df['Caption'] = df['Caption'].map(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "    if train:\n",
        "        df['LabelsVector'] = df['Labels'].map(lambda x: convert_label_to_vector(x))\n",
        "    return df "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG5a_3TmVmti"
      },
      "source": [
        "# generate dictionary to convert words into one hot vector\n",
        "def get_word_wrapper(df):\n",
        "    word_set = set()\n",
        "    for caption in df[\"Caption\"]:\n",
        "        for word in caption:\n",
        "            word_set.add(word)\n",
        "    word_set.add('[PAD]')\n",
        "    word_set.add('[UNKNOWN]')\n",
        "    word_list = list(word_set)\n",
        "    word_index = {}\n",
        "    ind = 0\n",
        "    for word in word_list:\n",
        "        word_index[word] = ind \n",
        "        ind += 1\n",
        "    return word_index, word_list"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Pjc4R9XXfF"
      },
      "source": [
        "# add padding so the vector size will be equal to seq_length\n",
        "def encode_and_pad(caption_arr, seq_length, word_index):\n",
        "    sent_encode = []\n",
        "    if len(caption_arr) > seq_length:\n",
        "        caption_arr = caption_arr[:seq_length]\n",
        "    for word in caption_arr:\n",
        "        try: \n",
        "            sent_encode.append(word_index[word])\n",
        "        except:\n",
        "            sent_encode.append(word_index[\"[UNKNOWN]\"])\n",
        "    if len(caption_arr) < seq_length:\n",
        "        delta = seq_length - len(caption_arr)\n",
        "        sent_encode.extend([word_index['[PAD]']] *  delta)\n",
        "    return np.array(sent_encode)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9m0cUpBbkB3"
      },
      "source": [
        "# Write a customized dataset class\n",
        "class ImageCaptionDatatset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, transform, seq_len,  word_index, is_train_data=True):\n",
        "        self.data = dataframe\n",
        "        self.is_train_data = is_train_data\n",
        "        if is_train_data:\n",
        "            self.targets = self.data.LabelsVector\n",
        "        self.img_paths = self.data.Image_Path \n",
        "        self.transform = transform\n",
        "        self.captions = dataframe.Caption\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        caption = self.captions[idx]\n",
        "        caption = encode_and_pad(caption, self.seq_len, word_index)\n",
        "        caption = torch.from_numpy(caption)\n",
        "        if self.is_train_data:\n",
        "            targets = torch.from_numpy(self.targets[idx])\n",
        "            return {\n",
        "                'img': image,\n",
        "                'caption': caption,\n",
        "                'targets': targets\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'img': image,\n",
        "                'caption': caption\n",
        "            }"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64B1x82CdyvT"
      },
      "source": [
        "# Define preprocessing for images data  \n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLs2a3AZryss"
      },
      "source": [
        "# get the labels when it is bigger than threshold\n",
        "def output_to_pred(y_hat_prob, threshold):\n",
        "    # y_hat_prob = torch.sigmoid(output)\n",
        "    zero = torch.zeros_like(y_hat_prob)\n",
        "    one = torch.ones_like(y_hat_prob)\n",
        "    y_hat = torch.where(y_hat_prob < threshold, zero, y_hat_prob)\n",
        "    y_hat = torch.where(y_hat >= threshold, one, y_hat)\n",
        "    return y_hat"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m9zTpt91zMX"
      },
      "source": [
        "# change one hot encoding of the predictions to string\n",
        "def vector_pred_to_string(arr):\n",
        "    result = \"\"\n",
        "    for i in range(20):\n",
        "        if arr[i] > 0:\n",
        "            result += str(i)\n",
        "            result += \" \"\n",
        "    return result.strip()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep0cU18nLHta"
      },
      "source": [
        "# Loading the pretrained w2v model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOAcWLKiWuLQ",
        "outputId": "3488fba3-c7b1-4c1a-f5a2-a84a7a196ab5"
      },
      "source": [
        "import gensim.downloader as api\n",
        "word_emb_model = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MCJpA2JLUxW"
      },
      "source": [
        "# Model Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qAPnu1UeM9j"
      },
      "source": [
        "class CNN_LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, emb_dim, emb_table, lstm_layers, lstm_hidden, num_class, pretrain_cnn='Resnet'):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        # loadding the pre-trained w2v matrix\n",
        "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.embed.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        self.embed.weight.requires_grad = False\n",
        "        if pretrain_cnn == 'Resnet':\n",
        "            resnet_model = models.resnet50(pretrained=True)\n",
        "            self.resnet = nn.Sequential(*list(resnet_model.children())[:-1]) # (batch,2048,1,1)\n",
        "            for param in self.resnet.parameters():\n",
        "                param.require_grad = False\n",
        "            input_size = 2048\n",
        "        if pretrain_cnn == 'VGG':\n",
        "            self.vgg = models.vgg16_bn(pretrained=True)\n",
        "            for param in self.vgg.parameters():\n",
        "                param.require_grad = False\n",
        "            input_size = 1000\n",
        "        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden, num_layers=lstm_layers, bidirectional=True, batch_first=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm1d(input_size + lstm_hidden * 2)\n",
        "        self.fc1 = nn.Linear(input_size + lstm_hidden * 2, 512)\n",
        "        self.bn2 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512, num_class)\n",
        "\n",
        "\n",
        "    def forward(self, caption, img):\n",
        "        img_feature = self.resnet(img)\n",
        "        img_feature = img_feature.squeeze(-1)\n",
        "        img_feature = img_feature.squeeze(-1) #((batch,2048)\n",
        "        caption_emb = self.embed(caption)\n",
        "        ouput, (h_n, _) = self.lstm(caption_emb) # h_n(layer * direction, batch, lstm_hidden)\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1) # (batch, lstm_hidden*2)\n",
        "        x = torch.cat((img_feature, hidden_out), 1)\n",
        "        x = self.bn1(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(self.bn2(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luUdJO75Lnpv"
      },
      "source": [
        "# Define hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVL6s93lecjw"
      },
      "source": [
        "lstm_layers = 1\n",
        "lstm_hidden = 128\n",
        "num_class = 20\n",
        "batch_size = 32\n",
        "num_epoch = 30\n",
        "learning_rate = 5\n",
        "num_epochs = 10\n",
        "pretrain_cnn='Resnet'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1KWPXquL1Ah"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJWEIy3nVsPI"
      },
      "source": [
        "# pre_processing the data\n",
        "train_df = data_preprocess(train_csv_dir, img_dir, True)\n",
        "test_df = data_preprocess(test_csv_dir, img_dir, False)\n",
        "word_index, word_list = get_word_wrapper(train_df)\n",
        "train_dataset = ImageCaptionDatatset(train_df, train_transform, seq_len,  word_index, True)\n",
        "test_dataset = ImageCaptionDatatset(test_df, test_transform, seq_len,  word_index, False)\n",
        "train_dataloader = DataLoader(train_dataset, drop_last=True, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
        "vocab_size = len(word_list)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GDFXyOSOw3W"
      },
      "source": [
        "# Generate embedding matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3mYmDF3aa9N",
        "outputId": "062a73b4-43fb-4779-d070-782c19ab1817"
      },
      "source": [
        "#generate matrix for embedding layer\n",
        "emb_dim = word_emb_model.vector_size\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list):\n",
        "    if word in word_emb_model:\n",
        "        emb_table.append(word_emb_model[word])\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "print(\"embedding_dim:\",emb_dim )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding_dim: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXuygt4zPAwA"
      },
      "source": [
        "# Training process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUQd56RnQS-E"
      },
      "source": [
        "## Define the training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPaCC5VbrDhk"
      },
      "source": [
        "def train_model(model, dataloader, criterion, optimizer, threshold=0.5, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    val_f1_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_f1 = 0.0\n",
        "    sigmoid = nn.Sigmoid()\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_f1 = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for data in dataloader:\n",
        "            img = data['img'].to(device)\n",
        "            caption = data['caption'].to(device)\n",
        "            labels = data['targets'].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(caption, img)\n",
        "                loss = criterion(outputs, labels)\n",
        "                output_pred = sigmoid(outputs)\n",
        "                preds = output_to_pred(output_pred, threshold)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * caption.size(0)\n",
        "            running_f1 += metrics.f1_score(preds.cpu().detach().numpy(), labels.cpu().detach().numpy(), average='macro')\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        epoch_f1 = running_f1 / len(dataloader)\n",
        "        print('Loss: {:.4f} f1: {:.4f}'.format(epoch_loss, epoch_f1))\n",
        "\n",
        "            # deep copy the model\n",
        "    if epoch_f1 > best_f1:\n",
        "        best_f1 = epoch_f1\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    val_f1_history.append(epoch_f1)\n",
        "\n",
        "    print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val f1: {:4f}'.format(best_f1))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_f1_history"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfNN_cUmsGjd",
        "outputId": "1e4127fe-4ab7-4cf9-a67b-1fbe255d7ab2"
      },
      "source": [
        "# https://discuss.pytorch.org/t/weighted-binary-cross-entropy/51156/2\n",
        "# calculate pos weight\n",
        "total_sample = len(train_df)\n",
        "positive_sample_distribution = np.zeros(20)\n",
        "for label in train_df['LabelsVector']:\n",
        "    positive_sample_distribution += label\n",
        "negative_sample_distribution = total_sample - positive_sample_distribution\n",
        "for i in range(len(positive_sample_distribution)):\n",
        "    if positive_sample_distribution[i] == 0:\n",
        "        # to avoid zero division\n",
        "        positive_sample_distribution[i]  = 0.01\n",
        "pos_weight = negative_sample_distribution / positive_sample_distribution\n",
        "pos_weight = torch.from_numpy(pos_weight)\n",
        "print(pos_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.9996e+06, 3.1596e-01, 2.4814e+01, 5.8735e+00, 2.2582e+01, 2.5545e+01,\n",
            "        2.0518e+01, 2.3567e+01, 1.2573e+01, 2.7787e+01, 1.9392e+01, 4.8662e+01,\n",
            "        2.9996e+06, 4.8580e+01, 1.1851e+02, 1.4510e+01, 2.6294e+01, 1.9976e+01,\n",
            "        1.8670e+01, 2.8408e+01], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aaphncPPury"
      },
      "source": [
        "## Define model, loss function and optimizer\n",
        "To add positional weight to the loss function, please the comment in the following cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi88JkmhsZYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "bf55195229764822817e19cc68789990",
            "d4626a5369c24940a6c7c9f82ce64e27",
            "b3f421e7291e48ee96df68e9cd4c1361",
            "2496c2e4de94475e879dd4a1c13a9eda",
            "795deb7799ca4efcb2b9dabf5844af67",
            "367e4891f7ac44a590e19155ac56a32d",
            "1771c62bbb0c48c8b60c88ac5918a8e5",
            "c833eb66c46c4517a735df805b4f47ce"
          ]
        },
        "outputId": "e55b0500-4a34-475f-fa47-04e7606e05bf"
      },
      "source": [
        "model = CNN_LSTM(vocab_size, emb_dim, emb_table, lstm_layers, lstm_hidden, num_class, pretrain_cnn)\n",
        "optimizer = optim.Adadelta(model.parameters(),lr=learning_rate, rho=0.9, eps=1e-06, weight_decay=0)\n",
        "# pos_weight = pos_weight.to(device)\n",
        "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf55195229764822817e19cc68789990",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-j4GnJ5QY8y"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlnBne8NZqIv",
        "outputId": "c66292f7-3ccd-455b-994c-b485170f68fc"
      },
      "source": [
        "model,val_f1_history = train_model(model, train_dataloader, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.2041 f1: 0.4567\n",
            "Epoch 1/29\n",
            "----------\n",
            "Loss: 2.1515 f1: 0.4586\n",
            "Epoch 2/29\n",
            "----------\n",
            "Loss: 2.0836 f1: 0.4642\n",
            "Epoch 3/29\n",
            "----------\n",
            "Loss: 2.0307 f1: 0.4684\n",
            "Epoch 4/29\n",
            "----------\n",
            "Loss: 1.9923 f1: 0.4713\n",
            "Epoch 5/29\n",
            "----------\n",
            "Loss: 1.9676 f1: 0.4727\n",
            "Epoch 6/29\n",
            "----------\n",
            "Loss: 1.9081 f1: 0.4777\n",
            "Epoch 7/29\n",
            "----------\n",
            "Loss: 1.8716 f1: 0.4816\n",
            "Epoch 8/29\n",
            "----------\n",
            "Loss: 1.8554 f1: 0.4820\n",
            "Epoch 9/29\n",
            "----------\n",
            "Loss: 1.8124 f1: 0.4877\n",
            "Epoch 10/29\n",
            "----------\n",
            "Loss: 1.7625 f1: 0.4915\n",
            "Epoch 11/29\n",
            "----------\n",
            "Loss: 1.7436 f1: 0.4927\n",
            "Epoch 12/29\n",
            "----------\n",
            "Loss: 1.7349 f1: 0.4938\n",
            "Epoch 13/29\n",
            "----------\n",
            "Loss: 1.6711 f1: 0.4996\n",
            "Epoch 14/29\n",
            "----------\n",
            "Loss: 1.6360 f1: 0.5041\n",
            "Epoch 15/29\n",
            "----------\n",
            "Loss: 1.6161 f1: 0.5045\n",
            "Epoch 16/29\n",
            "----------\n",
            "Loss: 1.6008 f1: 0.5079\n",
            "Epoch 17/29\n",
            "----------\n",
            "Loss: 1.7133 f1: 0.4999\n",
            "Epoch 18/29\n",
            "----------\n",
            "Loss: 1.7979 f1: 0.4889\n",
            "Epoch 19/29\n",
            "----------\n",
            "Loss: 1.6742 f1: 0.5013\n",
            "Epoch 20/29\n",
            "----------\n",
            "Loss: 1.6687 f1: 0.5012\n",
            "Epoch 21/29\n",
            "----------\n",
            "Loss: 1.5565 f1: 0.5086\n",
            "Epoch 22/29\n",
            "----------\n",
            "Loss: 1.4749 f1: 0.5189\n",
            "Epoch 23/29\n",
            "----------\n",
            "Loss: 1.4733 f1: 0.5211\n",
            "Epoch 24/29\n",
            "----------\n",
            "Loss: 1.4555 f1: 0.5204\n",
            "Epoch 25/29\n",
            "----------\n",
            "Loss: 1.3996 f1: 0.5278\n",
            "Epoch 26/29\n",
            "----------\n",
            "Loss: 1.3585 f1: 0.5307\n",
            "Epoch 27/29\n",
            "----------\n",
            "Loss: 1.3365 f1: 0.5331\n",
            "Epoch 28/29\n",
            "----------\n",
            "Loss: 1.3349 f1: 0.5340\n",
            "Epoch 29/29\n",
            "----------\n",
            "Loss: 1.2768 f1: 0.5394\n",
            "\n",
            "Training complete in 143m 50s\n",
            "Best val f1: 0.539372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUV9mGNyQiaf"
      },
      "source": [
        "## Save the model weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ja921phlNg5"
      },
      "source": [
        "torch.save(model.state_dict(), \"lstm_cnn_weight\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdYGd4hIQ8Nx"
      },
      "source": [
        "# Generate prediction for testing data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFQWQPT2tFwC"
      },
      "source": [
        "result = []\n",
        "sigmoid = nn.Sigmoid()\n",
        "model.eval()\n",
        "for data in test_dataloader: \n",
        "    img = data['img'].to(device)\n",
        "    caption = data['caption'].to(device)\n",
        "    output = model(caption, img)\n",
        "    y_hat = output_to_pred(sigmoid(output), threshold=0.5)\n",
        "    y_hat = y_hat.cpu().detach().numpy()\n",
        "    y_hat = y_hat.squeeze(0)\n",
        "    y_hat = vector_pred_to_string(y_hat)\n",
        "    result.append(y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mgz3nA07vyf1",
        "outputId": "7fa5b3af-23b9-40be-e1e1-bfc0578cd3b3"
      },
      "source": [
        "# save the result \n",
        "test_df[\"Labels\"] = result\n",
        "test_df = test_df.drop(columns=[\"Caption\", \"Image_Path\"])\n",
        "test_df.to_csv('prediction.csv', index=False)  \n",
        "print(\"finish writing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish writing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EMVqHWLvv5ct",
        "outputId": "0efe072c-3269-4e83-8a55-2d5016b333d5"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('prediction.csv') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ff677486-7c7f-4c4f-8bb5-b705fcab9c33\", \"prediction.csv\", 131249)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk5leDiowMee",
        "outputId": "c26af6b6-90f8-4039-8b5e-03a70718a9d6"
      },
      "source": [
        "print('csv downloaded')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "csv downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCJ-0Eq2izN9"
      },
      "source": [
        "# Model Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YP3T7uwMciQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1027ba6f-b682-4188-dbb4-8e4bfe46a22b"
      },
      "source": [
        "model_size = sum(p.numel() for p in model.parameters())  * 4/ (1024*1024)\n",
        "print('model size is ', model_size, \"MB\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model size is  97.49566650390625 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMMA_988kJmP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}